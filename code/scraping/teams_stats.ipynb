{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data for season 2016-2017 successfully extracted.\n",
      "All data for season 2017-2018 successfully extracted.\n",
      "All data for season 2018-2019 successfully extracted.\n",
      "All data for season 2019-2020 successfully extracted.\n",
      "All data for season 2020-2021 successfully extracted.\n",
      "All data for season 2021-2022 successfully extracted.\n",
      "All data for season 2022-2023 successfully extracted.\n",
      "All data for season 2023-2024 successfully extracted.\n",
      "Data saved to C:\\Users\\aldi\\Documents\\GitHub\\dream-team-fpl-prediction\\data\\teams_stats.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "from getpass import getuser\n",
    "import re\n",
    "\n",
    "# Set up Selenium options\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")  # Run Chrome in headless mode\n",
    "\n",
    "# Set up Chrome driver\n",
    "user = getuser()\n",
    "webdriver_service = Service(r'C:\\Users\\{}\\Downloads\\chromedriver.exe'.format(user))\n",
    "driver = webdriver.Chrome(service=webdriver_service, options=options)\n",
    "\n",
    "# Define the range of seasons\n",
    "start_season = 2016\n",
    "end_season = 2023\n",
    "\n",
    "# Create an empty DataFrame for team stats\n",
    "teams_stats = pd.DataFrame()\n",
    "\n",
    "# Loop through each season\n",
    "for season in range(start_season, end_season + 1):\n",
    "    # Format the URL for the current season\n",
    "    url = f\"https://fbref.com/en/comps/9/{season}-{season+1}/stats/{season}-{season+1}-Premier-League-Stats\"\n",
    "\n",
    "    # Load the webpage\n",
    "    driver.get(url)\n",
    "    sleep(3)  # Allow time for the page to load dynamically\n",
    "\n",
    "    # Get the page source and create a BeautifulSoup object\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "\n",
    "    # Find the table by id\n",
    "    table = soup.find(\"table\", id=\"stats_squads_standard_for\")\n",
    "\n",
    "    if table is None:\n",
    "        print(f\"Table not found on the webpage for season {season}-{season+1}.\")\n",
    "        continue\n",
    "\n",
    "    # Remove the tr element with class \"thead\"\n",
    "    thead_row = table.find(\"tr\", class_=\"thead\")\n",
    "    if thead_row:\n",
    "        thead_row.decompose()\n",
    "\n",
    "    # Extract column names\n",
    "    header_row = table.find(\"thead\").find_all(\"tr\")[1]  # Second row of the header\n",
    "    columns = []\n",
    "\n",
    "    # Retrieve the column names\n",
    "    for header in header_row.find_all(\"th\"):  # Include all columns\n",
    "        column_name = header.text.strip()\n",
    "\n",
    "        # Check for duplicate column names and modify them to make them unique\n",
    "        if column_name in columns:\n",
    "            column_name = f\"{column_name}_{columns.count(column_name) + 1}\"\n",
    "\n",
    "        columns.append(column_name)\n",
    "\n",
    "    # Extract team data\n",
    "    data_rows = table.find(\"tbody\").find_all(\"tr\")\n",
    "    team_data = []\n",
    "    for row in data_rows:\n",
    "        team = [cell.text for cell in row.find_all(\"td\")]\n",
    "        team_data.append(team)\n",
    "\n",
    "    # Extract squad names from href links\n",
    "    squad_names = []\n",
    "    for row in data_rows:\n",
    "        squad_link = row.find(\"a\", href=re.compile(r\"\\/squads\\/[a-zA-Z0-9]+\\/[a-zA-Z0-9\\-]+\"))\n",
    "        if squad_link:\n",
    "            squad_name = squad_link.text.strip()\n",
    "            squad_names.append(squad_name)\n",
    "\n",
    "    # Add season column name to column list\n",
    "    columns.insert(0, \"Season\")\n",
    "\n",
    "    # Add squad names to team data\n",
    "    for i, team in enumerate(team_data):\n",
    "        team.insert(0, f\"{season}-{season+1}\")\n",
    "        if i < len(squad_names):\n",
    "            team.insert(1, squad_names[i])\n",
    "\n",
    "    # Create a DataFrame for the team data of the current season\n",
    "    season_df = pd.DataFrame(team_data, columns=columns)\n",
    "\n",
    "    # Reset the index of the DataFrame\n",
    "    season_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Append the current season's team data to the overall teams_stats DataFrame\n",
    "    teams_stats = pd.concat([teams_stats, season_df], ignore_index=True)\n",
    "\n",
    "    print(f\"All data for season {season}-{season+1} successfully extracted.\")\n",
    "\n",
    "# Rename the '#PI' column to 'num_players'\n",
    "if '# Pl' in teams_stats.columns:\n",
    "    teams_stats.rename(columns={'#PI': 'num_players'}, inplace=True)\n",
    "\n",
    "# Remove the 'MP', 'Starts', 'Min', and '90s' columns\n",
    "columns_to_remove = ['MP', 'Starts', 'Min', '90s']\n",
    "teams_stats.drop(columns=[col for col in columns_to_remove if col in teams_stats.columns], inplace=True)\n",
    "\n",
    "# Remove empty rows\n",
    "teams_stats.dropna(how='all', inplace=True)\n",
    "\n",
    "# Remove rows where only the season and team variables are present\n",
    "teams_stats = teams_stats[~(teams_stats.drop([\"Season\", \"Squad\"], axis=1).isna().all(axis=1))]\n",
    "\n",
    "# Save data to a CSV file\n",
    "output_folder = fr'C:\\Users\\{user}\\Documents\\GitHub\\dream-team-fpl-prediction\\data'\n",
    "output_path = os.path.join(output_folder, 'teams_stats.xlsx')\n",
    "teams_stats.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"Data saved to {output_path}\")\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
