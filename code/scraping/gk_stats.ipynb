{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for season 2016-2017 successfully extracted.\n",
      "Data for season 2017-2018 successfully extracted.\n",
      "Data for season 2018-2019 successfully extracted.\n",
      "Data for season 2019-2020 successfully extracted.\n",
      "Data for season 2020-2021 successfully extracted.\n",
      "Data for season 2021-2022 successfully extracted.\n",
      "Data for season 2022-2023 successfully extracted.\n",
      "Data for season 2023-2024 successfully extracted.\n",
      "Keepers data saved to C:\\Users\\aldi\\Documents\\GitHub\\dream-team-fpl-prediction\\data\\keepers_stats.xlsx\n",
      "Advanced Keepers data saved to C:\\Users\\aldi\\Documents\\GitHub\\dream-team-fpl-prediction\\data\\advanced_keepers_stats.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "from getpass import getuser\n",
    "\n",
    "# Set up Selenium options\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")  # Run Chrome in headless mode\n",
    "\n",
    "# Set up Chrome driver\n",
    "user = getuser()\n",
    "webdriver_service = Service(r'C:\\Users\\{}\\Downloads\\chromedriver.exe'.format(user))\n",
    "driver = webdriver.Chrome(service=webdriver_service, options=options)\n",
    "\n",
    "# Define the range of seasons\n",
    "start_season = 2016\n",
    "end_season = 2023\n",
    "\n",
    "# Create empty DataFrames for each table\n",
    "keepers_stats = pd.DataFrame()\n",
    "advanced_keepers_stats = pd.DataFrame()\n",
    "\n",
    "# Loop through each season\n",
    "for season in range(start_season, end_season + 1):\n",
    "    # Format the URL for the current season\n",
    "    url = f\"https://fbref.com/en/comps/9/{season}-{season+1}/keepers/{season}-{season+1}-Premier-League-Stats\"\n",
    "\n",
    "    # Load the webpage\n",
    "    driver.get(url)\n",
    "    sleep(3)  # Allow time for the page to load dynamically\n",
    "\n",
    "    # Get the page source and create a BeautifulSoup object\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "\n",
    "    # Function to extract data from a table\n",
    "    def extract_table_data(table_id, season, exclude_columns=None):\n",
    "        table = soup.find(\"table\", id=table_id)\n",
    "\n",
    "        if table is None:\n",
    "            print(f\"Table '{table_id}' not found on the webpage for season {season}-{season+1}.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Remove the tr element with class \"thead\"\n",
    "        thead_row = table.find(\"tr\", class_=\"thead\")\n",
    "        if thead_row:\n",
    "            thead_row.decompose()\n",
    "\n",
    "        # Extract column names\n",
    "        header_row = table.find(\"thead\").find_all(\"tr\")[1]  # Second row of the header\n",
    "        columns = [\"Squad\"]  # Add Squad column as the first column\n",
    "\n",
    "        # Retrieve the remaining column names\n",
    "        for header in header_row.find_all(\"th\")[1:]:  # Exclude the first \"Rk\" column\n",
    "            column_name = header.text.strip()\n",
    "\n",
    "            # Check for duplicate column names and modify them to make them unique\n",
    "            if column_name in columns:\n",
    "                column_name = f\"{column_name}_{columns.count(column_name) + 1}\"\n",
    "\n",
    "            columns.append(column_name)\n",
    "\n",
    "        # Extract player data\n",
    "        data_rows = table.find(\"tbody\").find_all(\"tr\")\n",
    "        player_data = []\n",
    "        for row in data_rows:\n",
    "            # Extract the Squad (team name) from the <th> tag if it exists\n",
    "            squad_cell = row.find(\"th\")\n",
    "            squad_name = squad_cell.text.strip() if squad_cell else \"Unknown Squad\"\n",
    "\n",
    "            # Extract the rest of the data from the <td> tags\n",
    "            cells = row.find_all(\"td\")\n",
    "            player = [squad_name]  # Start the player list with the squad name\n",
    "\n",
    "            for cell in cells:\n",
    "                if 'data-stat=\"nationality\"' in str(cell):  # Check for Nation column\n",
    "                    nation_flag = cell.find(\"span\", class_=\"f-i\")\n",
    "                    if nation_flag and nation_flag.get(\"title\"):\n",
    "                        player.append(nation_flag.get(\"title\"))\n",
    "                    else:\n",
    "                        player.append(cell.text.strip())\n",
    "                else:\n",
    "                    player.append(cell.text.strip())\n",
    "\n",
    "            player_data.append(player)\n",
    "\n",
    "        # Convert player data to DataFrame\n",
    "        season_df = pd.DataFrame(player_data, columns=columns)\n",
    "\n",
    "        # Add season column to DataFrame\n",
    "        season_df.insert(0, \"Season\", f\"{season}-{season+1}\")\n",
    "\n",
    "        # Exclude specified columns from DataFrame\n",
    "        if exclude_columns:\n",
    "            season_df = season_df.drop(columns=exclude_columns)\n",
    "\n",
    "        return season_df\n",
    "\n",
    "    # Extract data for keepers and advanced keepers\n",
    "    keepers_df = extract_table_data(\"stats_squads_keeper_for\", season)\n",
    "    advanced_keepers_df = extract_table_data(\"stats_keeper\", season, exclude_columns=[\"Matches\"])\n",
    "\n",
    "    # Append the current season's player data to the overall DataFrames\n",
    "    keepers_stats = pd.concat([keepers_stats, keepers_df], ignore_index=True)\n",
    "    advanced_keepers_stats = pd.concat([advanced_keepers_stats, advanced_keepers_df], ignore_index=True)\n",
    "\n",
    "    print(f\"Data for season {season}-{season+1} successfully extracted.\")\n",
    "\n",
    "# Remove empty rows\n",
    "keepers_stats.dropna(how='all', inplace=True)\n",
    "advanced_keepers_stats.dropna(how='all', inplace=True)\n",
    "\n",
    "# Remove rows where only the season variable is present\n",
    "keepers_stats = keepers_stats[~(keepers_stats.drop(\"Season\", axis=1).isna().all(axis=1))]\n",
    "advanced_keepers_stats = advanced_keepers_stats[~(advanced_keepers_stats.drop(\"Season\", axis=1).isna().all(axis=1))]\n",
    "\n",
    "# Clean the Nation column in the advanced_keepers_stats DataFrame\n",
    "if 'Nation' in advanced_keepers_stats.columns:\n",
    "    advanced_keepers_stats['Nation'] = advanced_keepers_stats['Nation'].apply(lambda x: x.split()[-1])\n",
    "\n",
    "# Save data to Excel files\n",
    "output_folder = r'C:\\Users\\{}\\Documents\\GitHub\\dream-team-fpl-prediction\\data'.format(user)\n",
    "keepers_output_path = os.path.join(output_folder, 'keepers_stats.xlsx')\n",
    "advanced_keepers_output_path = os.path.join(output_folder, 'advanced_keepers_stats.xlsx')\n",
    "\n",
    "keepers_stats.to_excel(keepers_output_path, index=False)\n",
    "advanced_keepers_stats.to_excel(advanced_keepers_output_path, index=False)\n",
    "\n",
    "print(f\"Keepers data saved to {keepers_output_path}\")\n",
    "print(f\"Advanced Keepers data saved to {advanced_keepers_output_path}\")\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
